{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a203c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas openpyxl setfit sentence-transformers datasets joblib torch groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from groq import Groq # Import Groq client\n",
    "import time # To add slight delay if needed for API rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = #Place your GROQ_API_KEY here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf750b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# *** Please ensure this path is correct ***\n",
    "file_path = r\"C:\\Users\\punee\\Downloads\\final_diseases_dataset.xlsx\"\n",
    "model_save_path = \"disease_predictor_setfit_model\"\n",
    "label_mapping_save_path = \"disease_label_mapping.pkl\"\n",
    "# Note: We are removing the disease_info save path, as Groq will provide this info live.\n",
    "\n",
    "# Training parameters\n",
    "PRETRAINED_MODEL_NAME = \"sentence-transformers/paraphrase-mpnet-base-v2\" # Base model for SetFit\n",
    "NUM_ITERATIONS = 20\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS_HEAD = 1\n",
    "TEST_SET_SIZE = 0.2\n",
    "\n",
    "# Groq Configuration\n",
    "# Using Mixtral via Groq by default - generally good balance of speed/capability\n",
    "# Other options: \"llama3-8b-8192\", \"llama3-70b-8192\", \"gemma-7b-it\"\n",
    "GROQ_MODEL_NAME = \"meta-llama/llama-4-maverick-17b-128e-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Functions ---\n",
    "\n",
    "def load_and_prepare_data_for_setfit(file_path):\n",
    "    \"\"\"Loads data, checks columns, combines text for SetFit training.\"\"\"\n",
    "    print(f\"Loading dataset from: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: Dataset file not found at {file_path}\")\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(\"Columns found:\", df.columns.tolist())\n",
    "\n",
    "    # Define required columns for SetFit training\n",
    "    required_text_cols = ['Overview/Definition', 'Symptoms', 'Causes/Risk Factors']\n",
    "    required_label_col = 'Disease Name'\n",
    "    all_required_cols = required_text_cols + [required_label_col]\n",
    "\n",
    "    missing_cols = [col for col in all_required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Error: Missing required columns for SetFit training: {missing_cols}.\")\n",
    "\n",
    "    print(\"Required columns for training found.\")\n",
    "\n",
    "    # Combine text features\n",
    "    print(\"Combining text features...\")\n",
    "    df['combined_text'] = df[required_text_cols].fillna('').agg(' '.join, axis=1)\n",
    "    df['combined_text'] = df['combined_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "    # Prepare labels\n",
    "    df[required_label_col] = df[required_label_col].astype(str)\n",
    "    labels = df[required_label_col]\n",
    "    label_categories = labels.astype(\"category\")\n",
    "    label_codes = label_categories.cat.codes\n",
    "    label_mapping_int_to_name = dict(enumerate(label_categories.cat.categories))\n",
    "\n",
    "    print(f\"Found {len(label_mapping_int_to_name)} unique diseases for classification.\")\n",
    "\n",
    "    # Create Hugging Face Dataset (only text and label needed for training)\n",
    "    hf_dataset = Dataset.from_dict({\n",
    "        \"text\": df['combined_text'].tolist(),\n",
    "        \"label\": label_codes.tolist()\n",
    "    })\n",
    "\n",
    "    return hf_dataset, label_mapping_int_to_name\n",
    "    # No longer returning disease_info_lookup from here\n",
    "\n",
    "def train_disease_classifier(train_dataset, eval_dataset, label_mapping):\n",
    "    \"\"\"Trains the SetFit model for disease classification.\"\"\"\n",
    "    print(f\"\\n--- Starting SetFit Classifier Training using {PRETRAINED_MODEL_NAME} ---\")\n",
    "    num_classes = len(label_mapping)\n",
    "    print(f\"Number of classes (diseases): {num_classes}\")\n",
    "\n",
    "    model = SetFitModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "    trainer = SetFitTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        loss_class=CosineSimilarityLoss,\n",
    "        metric=\"accuracy\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_iterations=NUM_ITERATIONS,\n",
    "        num_epochs=NUM_EPOCHS_HEAD,\n",
    "        column_mapping={\"text\": \"text\", \"label\": \"label\"}\n",
    "    )\n",
    "\n",
    "    print(\"Training SetFit classifier...\")\n",
    "    trainer.train()\n",
    "\n",
    "    if eval_dataset:\n",
    "      print(\"Evaluating classifier performance...\")\n",
    "      metrics = trainer.evaluate()\n",
    "      print(f\"Evaluation Metrics: {metrics}\")\n",
    "    else:\n",
    "      metrics = None\n",
    "      print(\"No evaluation dataset provided, skipping evaluation.\")\n",
    "\n",
    "\n",
    "    print(\"Classifier training complete.\")\n",
    "    return model, metrics\n",
    "\n",
    "def get_info_from_groq(disease_name, symptoms_context=\"\"):\n",
    "    \"\"\"Queries Groq LLM for treatment and prevention info.\"\"\"\n",
    "    print(f\"\\n--- Querying Groq for info on: {disease_name} ---\")\n",
    "    try:\n",
    "        api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"GROQ_API_KEY environment variable not set.\")\n",
    "\n",
    "        client = Groq(api_key=api_key)\n",
    "\n",
    "        # Construct a prompt for the LLM\n",
    "        prompt_parts = [\n",
    "            f\"You are a helpful assistant providing general medical information.\",\n",
    "            f\"Based on the disease identified as '{disease_name}', please provide:\",\n",
    "            f\"1. General Treatment Options: (Common approaches, medications, therapies - mention this is not specific advice)\",\n",
    "            f\"2. General Prevention Measures: (Lifestyle advice, precautions)\",\n",
    "            f\"\\nContext (Symptoms provided by user, if any): '{symptoms_context}'\" if symptoms_context else \"\",\n",
    "            f\"\\nIMPORTANT: Frame the response clearly separating Treatment and Prevention. State explicitly that this information is general and not a substitute for professional medical advice.\",\n",
    "            f\"Keep the response concise and informative.\"\n",
    "         ]\n",
    "        prompt = \"\\n\".join(prompt_parts)\n",
    "\n",
    "\n",
    "        print(f\"Sending request to Groq model: {GROQ_MODEL_NAME}...\")\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=GROQ_MODEL_NAME,\n",
    "            # Optional parameters:\n",
    "            # temperature=0.7, # Adjust creativity vs. factuality\n",
    "            # max_tokens=500, # Limit response length\n",
    "            # top_p=1,\n",
    "            # stop=None,\n",
    "            # stream=False,\n",
    "        )\n",
    "\n",
    "        response_content = chat_completion.choices[0].message.content\n",
    "        print(\"Groq response received.\")\n",
    "\n",
    "        # Basic parsing attempt (can be improved based on observed LLM output format)\n",
    "        treatment_info = \"Could not parse Treatment info from response.\"\n",
    "        prevention_info = \"Could not parse Prevention info from response.\"\n",
    "\n",
    "        # Look for keywords to split - this is fragile and depends on LLM consistency\n",
    "        response_lower = response_content.lower()\n",
    "        treatment_keywords = [\"treatment options:\", \"general treatment:\", \"treatment:\", \"1. general treatment options:\"]\n",
    "        prevention_keywords = [\"prevention measures:\", \"general prevention:\", \"prevention:\", \"2. general prevention measures:\"]\n",
    "\n",
    "        treatment_start_idx = -1\n",
    "        prevention_start_idx = -1\n",
    "\n",
    "        for kw in treatment_keywords:\n",
    "             idx = response_lower.find(kw)\n",
    "             if idx != -1:\n",
    "                 treatment_start_idx = idx + len(kw)\n",
    "                 break\n",
    "\n",
    "        for kw in prevention_keywords:\n",
    "             idx = response_lower.find(kw)\n",
    "             if idx != -1:\n",
    "                 prevention_start_idx = idx + len(kw)\n",
    "                 break\n",
    "\n",
    "\n",
    "        if treatment_start_idx != -1 and prevention_start_idx != -1:\n",
    "            # Assume treatment comes before prevention\n",
    "            if treatment_start_idx < prevention_start_idx:\n",
    "                 # Find the start of the prevention section to mark the end of treatment\n",
    "                 end_of_treatment_idx = response_lower.find(next(kw for kw in prevention_keywords if kw in response_lower), treatment_start_idx)\n",
    "                 if end_of_treatment_idx != -1:\n",
    "                      treatment_info = response_content[treatment_start_idx:end_of_treatment_idx].strip()\n",
    "                 else: # Prevention keyword found, but maybe not after treatment keyword search start\n",
    "                      treatment_info = response_content[treatment_start_idx:].strip() # Take rest of string, hoping prevention is next\n",
    "\n",
    "                 prevention_info = response_content[prevention_start_idx:].strip()\n",
    "            else: # Assume prevention comes before treatment (less common based on prompt)\n",
    "                 end_of_prevention_idx = response_lower.find(next(kw for kw in treatment_keywords if kw in response_lower), prevention_start_idx)\n",
    "                 if end_of_prevention_idx != -1:\n",
    "                      prevention_info = response_content[prevention_start_idx:end_of_prevention_idx].strip()\n",
    "                 else:\n",
    "                      prevention_info = response_content[prevention_start_idx:].strip()\n",
    "\n",
    "                 treatment_info = response_content[treatment_start_idx:].strip()\n",
    "\n",
    "        elif treatment_start_idx != -1:\n",
    "            treatment_info = response_content[treatment_start_idx:].strip()\n",
    "        elif prevention_start_idx != -1:\n",
    "            prevention_info = response_content[prevention_start_idx:].strip()\n",
    "        else:\n",
    "            # If keywords aren't found, return the whole response as potentially treatment info\n",
    "            print(\"Warning: Could not reliably split Groq response into Treatment/Prevention sections.\")\n",
    "            treatment_info = response_content # Assign full response, user needs to read\n",
    "            prevention_info = \"(See above response)\"\n",
    "\n",
    "\n",
    "        # Add a small delay to avoid hitting rate limits if making many calls quickly\n",
    "        # time.sleep(1)\n",
    "\n",
    "        return treatment_info, prevention_info\n",
    "\n",
    "    except ValueError as ve: # Specifically catch the API key error\n",
    "        print(f\"Configuration Error: {ve}\")\n",
    "        return \"Error: API key not configured.\", \"Please set the GROQ_API_KEY environment variable.\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while querying Groq: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Error querying Groq: {e}\", \"\"\n",
    "\n",
    "\n",
    "def predict_disease_and_get_info(symptom_description):\n",
    "    \"\"\"Loads SetFit model, predicts disease, then queries Groq for info.\"\"\"\n",
    "    print(\"\\n--- Initiating Prediction ---\")\n",
    "    # Check if SetFit model files exist\n",
    "    if not os.path.exists(model_save_path) or not os.path.exists(label_mapping_save_path):\n",
    "        print(\"Error: SetFit model or label mapping file not found.\")\n",
    "        print(f\"Please ensure '{model_save_path}' and '{label_mapping_save_path}' exist.\")\n",
    "        print(\"You may need to run the script once to train and save the classifier.\")\n",
    "        return \"Error\", \"Classifier model files not found.\", \"Classifier model files not found.\"\n",
    "\n",
    "    try:\n",
    "        # 1. Load the SetFit classifier and label mapping\n",
    "        print(f\"Loading SetFit classifier from: {model_save_path}\")\n",
    "        model = SetFitModel.from_pretrained(model_save_path)\n",
    "\n",
    "        print(f\"Loading label mapping from: {label_mapping_save_path}\")\n",
    "        label_mapping_int_to_name = joblib.load(label_mapping_save_path)\n",
    "\n",
    "        # 2. Predict disease using SetFit\n",
    "        print(f\"Classifying disease based on input: '{symptom_description[:100]}...'\")\n",
    "        pred_label_int = model.predict([symptom_description])[0]\n",
    "        pred_label_int = int(pred_label_int.item() if hasattr(pred_label_int, 'item') else pred_label_int)\n",
    "        predicted_disease_name = label_mapping_int_to_name.get(pred_label_int, \"Unknown Disease\")\n",
    "        print(f\"SetFit Prediction: {predicted_disease_name}\")\n",
    "\n",
    "        # 3. Get Treatment/Prevention info from Groq LLM\n",
    "        treatment_info = \"Not available.\"\n",
    "        prevention_info = \"Not available.\"\n",
    "        if predicted_disease_name != \"Unknown Disease\":\n",
    "            treatment_info, prevention_info = get_info_from_groq(predicted_disease_name, symptom_description)\n",
    "        else:\n",
    "            treatment_info = \"Cannot fetch info for 'Unknown Disease'.\"\n",
    "            prevention_info = \"Cannot fetch info for 'Unknown Disease'.\"\n",
    "\n",
    "        return predicted_disease_name, treatment_info, prevention_info\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction pipeline: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return \"Error\", f\"Prediction pipeline failed: {e}\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Optional Training Phase ---\n",
    "    # You can comment this section out if you have already trained and saved the model\n",
    "    # Or add a check if model files exist, and skip training if they do.\n",
    "    run_training = True # Set to False to skip training if model is saved\n",
    "    if os.path.exists(model_save_path) and os.path.exists(label_mapping_save_path):\n",
    "        print(\"Found existing SetFit model and mapping. Skipping training.\")\n",
    "        print(f\"Model: {model_save_path}\")\n",
    "        print(f\"Mapping: {label_mapping_save_path}\")\n",
    "        run_training = False\n",
    "        # You might want to add a command-line argument to force retraining, e.g. `python script.py --train`\n",
    "\n",
    "    if run_training:\n",
    "        try:\n",
    "            # 1. Load and Prepare Data for SetFit\n",
    "            full_dataset, label_mapping = load_and_prepare_data_for_setfit(file_path)\n",
    "\n",
    "            # 2. Split data\n",
    "            print(f\"Splitting data into Train ({1-TEST_SET_SIZE:.0%}) / Eval ({TEST_SET_SIZE:.0%})...\")\n",
    "            labels_for_split = full_dataset['label']\n",
    "            unique_labels, counts = np.unique(labels_for_split, return_counts=True)\n",
    "            min_samples_per_class = counts.min() if len(counts) > 0 else 0\n",
    "\n",
    "            eval_dataset = None\n",
    "            if TEST_SET_SIZE > 0 and len(full_dataset) > 1:\n",
    "                if min_samples_per_class < 2 :\n",
    "                    print(f\"Warning: Some classes have only {min_samples_per_class} sample. Cannot stratify split reliably.\")\n",
    "                    # Decide: Use non-stratified or use all data? Using non-stratified.\n",
    "                    print(\"Using non-stratified split.\")\n",
    "                    split_datasets = full_dataset.train_test_split(test_size=TEST_SET_SIZE, seed=42) # No stratify\n",
    "                    train_dataset = split_datasets['train']\n",
    "                    eval_dataset = split_datasets['test']\n",
    "                else:\n",
    "                    # Proceed with stratified split\n",
    "                    split_datasets = full_dataset.train_test_split(test_size=TEST_SET_SIZE, seed=42, stratify_by_column='label')\n",
    "                    train_dataset = split_datasets['train']\n",
    "                    eval_dataset = split_datasets['test']\n",
    "                print(f\"Training set size: {len(train_dataset)}\")\n",
    "                print(f\"Evaluation set size: {len(eval_dataset)}\")\n",
    "            else:\n",
    "                print(\"Using full dataset for training. No evaluation split created.\")\n",
    "                train_dataset = full_dataset\n",
    "                # eval_dataset remains None\n",
    "\n",
    "            # 3. Train the SetFit Classifier\n",
    "            eval_ds_for_train = eval_dataset if eval_dataset else train_dataset # Use train if no eval split\n",
    "            trained_model, training_metrics = train_disease_classifier(train_dataset, eval_ds_for_train, label_mapping)\n",
    "\n",
    "            # 4. Save the results (Model and Label Mapping only)\n",
    "            print(\"\\n--- Saving Training Artifacts ---\")\n",
    "            print(f\"Saving SetFit model to '{model_save_path}'...\")\n",
    "            trained_model.save_pretrained(model_save_path)\n",
    "            print(f\"Saving label mapping to '{label_mapping_save_path}'...\")\n",
    "            joblib.dump(label_mapping, label_mapping_save_path)\n",
    "            print(\"SetFit classifier model and mapping saved successfully.\")\n",
    "\n",
    "        except (FileNotFoundError, ValueError, ImportError) as e:\n",
    "            print(f\"\\n--- Setup/Training Error ---\")\n",
    "            print(e)\n",
    "            print(\"Please check file path, Excel columns, required libraries, and GROQ_API_KEY environment variable.\")\n",
    "            exit() # Stop if training fails\n",
    "        except Exception as e:\n",
    "            print(f\"\\n--- An Unexpected Error Occurred During Setup/Training ---\")\n",
    "            print(e)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            exit() # Stop if training fails\n",
    "\n",
    "\n",
    "    # --- Interactive Prediction Phase ---\n",
    "    print(\"\\n--- Interactive Disease Prediction & Info Retrieval ---\")\n",
    "    # Check for Groq API key availability before starting interactive part\n",
    "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "         print(\"\\n*** WARNING: GROQ_API_KEY environment variable not detected. ***\")\n",
    "         print(\"   Treatment/Prevention info retrieval via Groq will fail.\")\n",
    "         print(\"   Please set the environment variable and restart the script.\")\n",
    "\n",
    "    print(\"\\nEnter symptoms or description. Type 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nSymptoms: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        if not user_input.strip():\n",
    "            print(\"Please enter some text.\")\n",
    "            continue\n",
    "\n",
    "        predicted_disease, treatment, prevention = predict_disease_and_get_info(user_input)\n",
    "\n",
    "        print(\"\\n--- Prediction & Information ---\")\n",
    "        print(f\"Predicted Disease (using SetFit + local data): {predicted_disease}\")\n",
    "        print(\"\\n[!] Disclaimer: The predicted disease is based on the fine-tuned model. Both the prediction and the generated information below are NOT substitutes for professional medical advice. Always consult a qualified healthcare professional.\")\n",
    "        print(f\"\\nTreatment Info (Generated by AI via Groq - General Info):\\n{treatment}\")\n",
    "        print(f\"\\nPrevention Info (Generated by AI via Groq - General Info):\\n{prevention}\")\n",
    "        print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Set your Groq model and API key\n",
    "GROQ_MODEL_NAME = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Create Groq client\n",
    "client = Groq(api_key=API_KEY)\n",
    "\n",
    "# Initialize system context for a smart medical chatbot\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are an intelligent, caring AI medical assistant named MedBot. \"\n",
    "        \"You are integrated into a diagnostic system that uses symptom inputs and medical models to help users understand their health. \"\n",
    "        \"Be conversational, empathetic, and helpful. Answer symptom-related questions, guide users through general medical concerns, and explain what-if scenarios. \"\n",
    "        \"Also assist in interpreting results from an AI-powered system with disease predictions, wearable data, or scenario simulations. \"\n",
    "        \"Always remind users that you are not a substitute for professional medical advice.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Chat history\n",
    "history = [system_message]\n",
    "\n",
    "print(\"\\nðŸ©º Welcome to MedBot â€“ Your AI Medical Chat Assistant (Groq Powered)\")\n",
    "print(\"Type 'exit' to quit. Ask about symptoms, health concerns, or anything related to diagnosis, treatment, or wellness.\\n\")\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"MedBot: Stay healthy! Remember to consult a doctor for medical decisions.\")\n",
    "        break\n",
    "\n",
    "    # Add user input to chat history\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Send conversation to Groq\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=GROQ_MODEL_NAME,\n",
    "            messages=history\n",
    "        )\n",
    "        bot_reply = response.choices[0].message.content\n",
    "        history.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "        print(f\"\\nMedBot: {bot_reply}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
